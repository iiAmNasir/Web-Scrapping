{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WebScrapping_UsingScrapy.ipynb","provenance":[],"authorship_tag":"ABX9TyOo0juPlRHApbAwC+RMWiPQ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"qfovV-gFRsOg"},"source":["try:\r\n","    import scrapy\r\n","except:\r\n","    !pip install scrapy\r\n","    import scrapy\r\n","from scrapy.crawler import CrawlerProcess\r\n","from scrapy.linkextractors import LinkExtractor\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","links=[]\r\n","class RustSpider(scrapy.Spider):\r\n","    name = \"cnn\"\r\n","    allowed_domains = [\"cnn.com\"]\r\n","    start_urls = ('https://edition.cnn.com/',)\r\n","    \r\n","    def parse(self, response):\r\n","        extractor = LinkExtractor(allow_domains='cnn.com')\r\n","        global links\r\n","        links=(extractor.extract_links(response))\r\n","        \r\n","process = CrawlerProcess({\r\n","    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\r\n","})\r\n","process.crawl(RustSpider)\r\n","process.start()"],"execution_count":null,"outputs":[]}]}